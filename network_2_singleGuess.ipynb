{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"network_2_singleGuess.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNy2cQwdzS9LzbPozbZqyCs"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nAKc0sN8IUjf","colab_type":"text"},"source":["# 0: Libraries and Functionalities"]},{"cell_type":"code","metadata":{"id":"AkXXqSXogDV8","colab_type":"code","colab":{}},"source":["#import all the needed libraries and initialize them\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","import librosa as lr\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","#playing audio\n","import IPython.display as ipd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsRn9igyxjKH","colab_type":"code","colab":{}},"source":["# make list variables for the needed files these are like global variables\n","audio_files = []\n","file_ids = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"39LlzDiCRu68","colab_type":"code","colab":{}},"source":["class StopWatch():\n","\n","    def __init__(self):\n","        self.start_time = time.time()\n","\n","    def give(self):\n","        time_diff = round(time.time() - self.start_time)\n","        hour = str(time_diff // 3600).zfill(2)\n","        minute = str((time_diff % 3600) // 60).zfill(2)\n","        second = str(time_diff % 60).zfill(2)  # Same as time_diff - (minutes * 60)\n","        \n","        return f'[{hour}:{minute}:{second}]'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3KTgtahCiYz","colab_type":"code","outputId":"1c191735-e367-4168-d0e0-222cb4bde0c7","executionInfo":{"status":"ok","timestamp":1592008430025,"user_tz":240,"elapsed":19951,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUD16OodDmFE","colab_type":"code","outputId":"3db8ec97-7940-4757-e462-231d8a3282fc","executionInfo":{"status":"ok","timestamp":1592008430373,"user_tz":240,"elapsed":20292,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd 'drive/My Drive/Music + AI Project/01 - [NN1] LSTM Generation'\n","#%cd 'Music + AI Project/01 - [NN1] LSTM Generation'\n","#%ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Music + AI Project/01 - [NN1] LSTM Generation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kC0Guf0zc9iT","colab_type":"code","colab":{}},"source":["global_sr = int(44100/500)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tusfkPPlftXR"},"source":["# 4: The Neural Network (Sample Output)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ui5GqhFwftXX"},"source":["## 4.1: Reading features"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"726500d8-b3da-41ab-8287-445a5e872760","executionInfo":{"status":"ok","timestamp":1592008431595,"user_tz":240,"elapsed":21504,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"id":"5VAa7cAPftXa","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#read the fetures if not in memeory\n","all_feature_matrix = np.load(\"data/feature_data.npy\")\n","print(\"Feature Reading Completed!\")\n","print(\"Shape of the features: \", all_feature_matrix.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Feature Reading Completed!\n","Shape of the features:  (265, 880)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vqwUzCw7ftXk"},"source":["## 4.2: Setting NN Variables and Define Model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lf6CO7o7ftXm"},"source":["**Variables**:\n","\n","Variable name | Description | Can I change this?\n","--- | --- | ---\n","sr | sampling rate at which the song has been read at, and helps in setting network nodes | Yes (Keep consistent with input)\n","batch_num | how many batches should a chunk be converted into? | Yes\n","input_size | calculates the input layer nodes for the network | No\n","hidden_size | calculates the hidden layer nodes for the network | Yes (Only the factor)\n","output_size | calculates the output layer nodes for the network | Yes (Depends on network check)\n","num_layers | setting default layers to 1 for now | No\n","dropout_per | what percent of the layers need to be droped while training | Yes\n","learning_rate | the rate at which the network learns outputs | Yes (exponent form)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iO1D0McWftXn","colab":{}},"source":["# Setting up variables for the neural networks\n","sr = global_sr\n","batch_num = 2\n","input_size = int(sr*batch_num)\n","hidden_size = int(input_size * 2.8)\n","output_size = 1\n","num_layers = 1\n","dropout_per = 0.5\n","learning_rate = 1e-3\n","\n","# setting the device to run the code to GPU is avaialble\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HfLP9RnHftXu","colab":{}},"source":["# definfng the Neural network class\n","class BasicRNN(nn.Module):\n","\n","    # initializaing the network\n","    # declaring all the needed layers\n","    def __init__(self):\n","        super(BasicRNN,self).__init__()\n","\n","        # an lstm layer for input to hidden layers\n","        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)\n","        # hidden to putput\n","        self.out = nn.Linear(hidden_size, output_size)\n","        # a dropdout layer between the hideen and output layer \n","        self.drop = nn.Dropout(p=dropout_per)\n","\n","        # making the hidden layer and setting it to zero\n","        self.hidden = ((torch.zeros(num_layers, 1, hidden_size)), (torch.zeros(num_layers, 1, hidden_size)))\n","\n","    def reset_hidden(self):\n","        # resetting the hidden layer to zero, which can be done after backpropogation\n","        self.hidden = ((torch.zeros(num_layers, 1, hidden_size)), (torch.zeros(num_layers, 1, hidden_size)))\n","\n","    #setting the network layers in order\n","    def forward(self, seq):\n","        \n","        # here, the view is adding anoher dimention to the sequence being passed to the network\n","        out, self.hidden = self.rnn(seq.view(1,1,-1))\n","        out = self.drop(out)\n","        out = self.out(out.view(1,-1))\n","        \n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"43cDNEEBftXz"},"source":["## 4.3: Validate the Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L5edjmUmftXz","colab":{}},"source":["def validate_network(showError = False):\n","\n","    # making a list of all the batch number which belong to the testing groups\n","    test_list = [x for x in range(total_train,total_train+total_test)]\n","    loss_by_batch = []\n","\n","    # setting the network t evaluation\n","    net.eval()\n","\n","    # iterate through the testing bacthes\n","    for i, batch in enumerate(test_list):\n","\n","        # set loss to to zero after each batch iteration\n","        loss = 0\n","\n","        # iterate over the small chunks to pass into the network and hear their output\n","        for j in range(total_mini_chunks):\n","            \n","            # get the needed input and actual output values \n","            input_matrix = torch.FloatTensor(all_feature_matrix[batch][j:input_size+j]).to(device)\n","            val_output = torch.FloatTensor(np.array(all_feature_matrix[batch][input_size+j+1])).to(device)\n","\n","            # get the network output\n","            nn_output = net(input_matrix)\n","\n","            # check the network output and add the loss\n","            loss += loss_function(nn_output, val_output.view(1,-1).long())\n","\n","        # add the loss to a list which contains loss for all batches\n","        loss_by_batch.append(loss)\n","\n","    # plot the graph of the batch loss as a line graph\n","    if showError:\n","        plt.plot(loss_by_batch)\n","        plt.ylabel('Loss by batch')\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Moysn3cLftX4"},"source":["## 4.4: Generate some Music"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qn2QouzGftX5","colab":{}},"source":["def generate_sample_song(song_length_seconds, song_name = \"test_output.wav\", showSignal = False):\n","        \n","    # start with a random seed\n","    batch_seed = random.randint(0,len(all_feature_matrix))\n","    sample_seed = 3\n","\n","    # variables for the song output\n","    # changing the seconds will automatically calculate the needed samples for the song and total iterations for the loop\n","    seconds = song_length_seconds\n","    song_samples = int(seconds * sr)\n","    total_iterations = song_samples - input_size - 2\n","\n","    # get the features for the seed\n","    input_seed = torch.FloatTensor(all_feature_matrix[batch_seed][input_size*sample_seed:input_size*(sample_seed+1)]).to(device)\n","\n","    # make a zero variable to input the song into\n","    song = np.zeros(song_samples)\n","    song[0:input_size] = input_seed.cpu().detach().numpy()\n","\n","    # set the network to evaluation mode\n","    net.eval()\n","\n","    # loop through the needed iterations\n","    for i in range(total_iterations):\n","\n","        input_seed = torch.FloatTensor(song[i:input_size + i]).to(device)\n","\n","        if (i+1) % (sr*2) == 0:\n","            batch_seed = random.randint(0,len(all_feature_matrix))\n","            input_seed = torch.FloatTensor(all_feature_matrix[batch_seed][input_size*sample_seed:input_size*(sample_seed+1)]).to(device)\n","\n","\n","        # get the output from the network\n","        nn_output = net(input_seed)\n","\n","        # add the current output to the song\n","        song[input_size + i] = nn_output.cpu().detach().numpy()\n","\n","    # up sample the song to the needed samples\n","    song = lr.core.resample(song, sr, 22050)\n","    #save the song as a test output\n","    lr.output.write_wav(song_name, song, 22050)\n","\n","    # plot the signal plot of the song as a line graph\n","    if showSignal:\n","        plt.plot(song)\n","        plt.ylabel('Song Sound')\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yj-DbSNGftX8"},"source":["## 4.5: Train the Model"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b6c3704d-8b1a-4adf-a5a5-cb450447d2b4","executionInfo":{"status":"error","timestamp":1592008492874,"user_tz":240,"elapsed":82771,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"id":"KSkTsvm8ftX-","colab":{"base_uri":"https://localhost:8080/","height":417}},"source":["# set the number of epoch and traininng perecntage of the dataset\n","epochs = 100\n","training_per = 0.85\n","test_network = 1\n","total_mini_chunks = len(all_feature_matrix[0])-input_size-1\n","\n","# this calculates the total number of chucks to be used for training and testing\n","total_train = int(all_feature_matrix.shape[0] * training_per)\n","total_test = all_feature_matrix.shape[0] - total_train\n","\n","# makes a list of all chunk numbers which will be used to train the network\n","shuffle_list = [x for x in range(total_train)]\n","\n","# make the network and put it on GPU\n","net = BasicRNN().float().to(device)\n","\n","# define an optimizer and loss function\n","# this can be changed as per the model\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","loss_function = nn.MSELoss()\n","\n","# making a stopwatch to count time\n","watch = StopWatch()\n","\n","# loop for all the epochs\n","for epoch in range(epochs):\n","\n","    # shufftle the batchs so the network is not used to the sequence\n","    random.shuffle(shuffle_list)\n","    # reset the epoch loss\n","    epoch_loss = 0\n","\n","    # run for all the chunks\n","    for i, batch in enumerate(shuffle_list):\n","\n","        # reset the hidden layers and remove all gradients after each batch iteration, which also considers back propogation\n","        net.reset_hidden()\n","        net.zero_grad()\n","        loss = 0\n","\n","        # loop for all the possible input-output training neede for the network\n","        for j in range(total_mini_chunks):\n","            \n","            # make the input and validation output tensors\n","            input_matrix = torch.FloatTensor(all_feature_matrix[batch][j:input_size+j]).to(device)\n","            val_output = torch.FloatTensor(np.array(all_feature_matrix[batch][input_size+j+1])).to(device)\n","\n","            # get the network output\n","            nn_output = net(input_matrix)\n","\n","            # calculate the loss from the nnetwork output and valid output\n","            loss += loss_function(nn_output, val_output.view(1,-1))\n","            epoch_loss += loss\n","\n","        # back propogate through the network with the accumulated error and optimizer\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print the state of the network after a few chunks are worked om\n","        if (i+1) % 20 == 0:\n","            print(f'{watch.give()} Epoch {epoch + 1}; Batch {i + 1}; Loss {round(float(loss),6)}')\n","\n","    # a print to now the end of an epoch and its loss\n","    print(f'{watch.give()} Epoch {epoch + 1} completed! Total Loss: {round(float(epoch_loss),6)}')\n","\n","    # after a few epochs check with the testing of the network and also generate a song sample\n","    if (epoch+1) % test_network == 0:\n","        validate_network(True)\n","        generate_sample_song(5, f'rc_single_wav_output/rc_e{epoch+1}.wav',True)\n","        net.train()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[00:00:51] Epoch 1; Batch 20; Loss 0.812983\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4607b0721a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# back propogate through the network with the accumulated error and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}